# Zero Configuration
# This file is copied to workspace/config.toml when running Zero

profile = "sre_support_engineer"

[profiles.sre_support_engineer]
model_provider = "litellm"
model_reasoning_effort = "low"
sandbox_mode = "workspace-write"
approval_policy = "never"

[profiles.sre_support_engineer.sandbox_workspace_write]
writable_roots = []
network_access = false

# ============================================================================
# MCP Servers
# ============================================================================

[mcp_servers.sre_utils]
command = "python"
args = ["-m", "sre_tools.cli.sre_utils"]

[mcp_servers.sre_utils.env]
PYTHONPATH = "python"

# ============================================================================
# Model Provider - Local LiteLLM Proxy
# ============================================================================
# LiteLLM routes to OpenRouter (o3-mini, claude, gemini, etc.)
# Run: uv run litellm --config config.yaml

[model_providers.litellm]
name = "LiteLLM Proxy"
base_url = "http://localhost:4000"
# env_key = "DUMMY_KEY_NEED_NOT_BE_UPDATED"
wire_api = "chat"
max_output_tokens = 16384
