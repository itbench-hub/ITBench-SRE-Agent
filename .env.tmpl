# ==============================================================================
# ITBench SRE Agent - Environment Configuration Template
# ==============================================================================
# Copy this file to .env and fill in your actual values
# Never commit .env to version control!
#
# Usage:
#   cp .env.tmpl .env
#   # Edit .env with your values
#   source .env  # Load before running Zero
#   uv run zero exec ...

# ==============================================================================
# Model Provider API Keys (LiteLLM)
# ==============================================================================
# LiteLLM Proxy uses these keys to route requests to model providers
# See litellm_config.yaml for the full model configuration

# OpenRouter (PRIMARY - supports GPT, Claude, Gemini, and more)
# Get your key at: https://openrouter.ai/keys
# Used by: gpt-5.2, claude-4-5-opus-latest, gemini-3-pro-preview, gemini-2.5-pro
OPENROUTER_API_KEY=your-openrouter-key-here

# OpenAI (OPTIONAL - for direct OpenAI API access)
# Get your key at: https://platform.openai.com/api-keys
# Used by: gpt-5.2-direct model (bypasses OpenRouter)
# OPENAI_API_KEY=your-openai-key-here

# WatsonX (OPTIONAL - only if using IBM WatsonX models)
# Used by: gpt-oss-120b-on-watsonx model
# IBMCLOUD_WATSONX_API_KEY=your-watsonx-api-key
# IBMCLOUD_WATSONX_PROJECT_ID=your-project-id
# IBMCLOUD_WATSONX_BASE_URL=https://us-south.ml.cloud.ibm.com

# ==============================================================================
# Judge Configuration (LLM-as-a-Judge for evaluations)
# ==============================================================================
# The judge evaluates agent outputs against ground truth
# Default: Uses local LiteLLM proxy (set in model_leaderboard.toml)
# Only set these if running itbench-eval directly without the leaderboard

# Judge via LiteLLM proxy (default - recommended)
# JUDGE_BASE_URL=http://localhost:4000
# JUDGE_API_KEY=dummy
# JUDGE_MODEL=gemini-2.5-pro

# Judge via OpenRouter directly (alternative)
# JUDGE_BASE_URL=https://openrouter.ai/api/v1
# JUDGE_API_KEY=${OPENROUTER_API_KEY}
# JUDGE_MODEL=google/gemini-2.5-pro

# ==============================================================================
# ClickHouse MCP Server Configuration
# ==============================================================================
# Used for querying ClickHouse databases in SRE investigations
# The ClickHouse MCP server is included in the default installation

CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=

# Production example (commented out):
# CLICKHOUSE_HOST=production.clickhouse.company.com
# CLICKHOUSE_PORT=8123
# CLICKHOUSE_USER=sre_readonly
# CLICKHOUSE_PASSWORD=secure_password_here

# ==============================================================================
# Kubernetes MCP Server Configuration
# ==============================================================================
# Points to your kubeconfig file for kubectl operations
# The Kubernetes MCP server is included in the default installation

# Default: Uses ~/.kube/config (uncomment to override)
# KUBECONFIG=/path/to/your/kubeconfig

