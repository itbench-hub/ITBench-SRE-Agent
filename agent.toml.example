# SRE Agent Configuration

# Model Configuration
## For OpenRouter, use the full model path.
# model_name = "x-ai/grok-4" # really bad at calling the tools
# model_name = "openrouter/moonshotai/kimi-k2-thinking" # bad at calling the tools
# model_name = "openrouter/qwen/qwen3-max" # good at tool calling
# model_name = "openrouter/anthropic/claude-opus-4.5"
# model_name = "openrouter/openai/o4-mini-high"
# model_name = "openrouter/openai/gpt-5.1-codex"
# model_name = "openrouter/google/gemini-2.5-pro"
# model_name = "openrouter/openai/gpt-5.1" # seems to be overfitted to aiopslab/itbench

## ete models
#model_name = "litellm_proxy/GCP/gemini-2.5-pro"
#model_name = "litellm_proxy/gcp/gemini-3-pro-preview"
#model_name = "litellm_proxy/Azure/gpt-5.1-2025-11-13"
model_name = "litellm_proxy/aws/claude-opus-4-5"

# Agent execution limit (each tool call = 2 steps in the graph)
# Increase this if investigation is being cut short
recursion_limit = 100
max_tool_output_length = 10000 # can be increased for gemini models

[llm_config]
# open router
# base_url = "https://openrouter.ai/api/v1"
# api_key = "YOUR KEY" 


[file_tools]
enabled = true
base_dir = "/Users/saurabhjha/projects/open_source/ITBench-Snapshots/snapshots/sre/v0.1-ca9707b2-8b70-468b-a8f9-9658438f80b1/Scenario-33"
enable_read_file = true
enable_edit_file = false # Read-only by default for safety
enable_create_file = false
enable_delete_file = false
enable_list_directory = true

[search_tools]
enabled = true
max_results = 20
enable_grep = true
enable_file_search = true
enable_codebase_search = true

[system_tools]
enabled = true
enable_run_terminal_cmd = true # Enable with caution

[blacklist]
# Files matching these patterns cannot be read, grepped, or listed
# Supports glob patterns: *, ?, [seq], [!seq]
patterns = [
    "ground_truth*.yaml",
    "*.secret",
    "*.key",
    ".env*",
]
